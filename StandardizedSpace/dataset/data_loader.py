import os
import torch
import numpy as np
import pickle
from tqdm import tqdm
from transformers import Wav2Vec2Processor
import librosa
from collections import defaultdict
from torch.utils import data 
import pickle as pkl
import cv2
import csv

class Dataset(data.Dataset):
    """Custom data.Dataset compatible with data.DataLoader."""
    def __init__(self, data_type="train",read_audio=False):
        #self.data = data
        #self.len = len(self.data)
        #self.subjects_dict = subjects_dict
        self.data_type = data_type
        #self.one_hot_labels = np.eye(len(subjects_dict["train"]))
        self.read_audio = read_audio

    def load_3dmm_params(self,index):
        # load init codes from the results generated by solving 3DMM rendering opt.
        #nl3dmm_para_dict = self.hdf['nl3dmm']
        dmm_name=str(index) + '_nl3dmm.pkl'
        para_3dmm_path = os.path.join('/home/dataset/Obama_q/png',dmm_name)
        with open(para_3dmm_path, "rb") as f: nl3dmm_para_dict = pkl.load(f)
        base_code = nl3dmm_para_dict["code"].float().detach().unsqueeze(0).cuda()
        base_expr_gen=base_code[:, 100:179].squeeze(1)
        return base_expr_gen
        '''
        dmm_name=str(index)+'_nl3dmm.pkl'
        para_3dmm_path = os.path.join(self.path,dmm_name)
        with open(para_3dmm_path, "rb") as f: nl3dmm_para_dict = pkl.load(f)

        base_code = nl3dmm_para_dict["code"].float().detach().unsqueeze(0).to(self.device)
        
        base_iden = base_code[:, :self.opt.iden_code_dims]
        base_expr = base_code[:, self.opt.iden_code_dims:self.opt.iden_code_dims + self.opt.expr_code_dims]
        base_text = base_code[:, self.opt.iden_code_dims + self.opt.expr_code_dims:self.opt.iden_code_dims 
                                                            + self.opt.expr_code_dims + self.opt.text_code_dims]
        base_illu = base_code[:, self.opt.iden_code_dims + self.opt.expr_code_dims + self.opt.text_code_dims:]

        self.base_c2w_Rmat =  nl3dmm_para_dict["c2w_Rmat"].float().detach().unsqueeze(0)
        self.base_c2w_Tvec =  nl3dmm_para_dict["c2w_Tvec"].float().detach().unsqueeze(0).unsqueeze(-1)
        self.base_w2c_Rmat =  nl3dmm_para_dict["w2c_Rmat"].float().detach().unsqueeze(0)
        self.base_w2c_Tvec =  nl3dmm_para_dict["w2c_Tvec"].float().detach().unsqueeze(0).unsqueeze(-1)

        temp_inmat =  nl3dmm_para_dict["inmat"].detach().unsqueeze(0)
        temp_inmat[:, :2, :] *= (self.featmap_size / self.gt_img_size)
        
        temp_inv_inmat = torch.zeros_like(temp_inmat)
        temp_inv_inmat[:, 0, 0] = 1.0 / temp_inmat[:, 0, 0]
        temp_inv_inmat[:, 1, 1] = 1.0 / temp_inmat[:, 1, 1]
        temp_inv_inmat[:, 0, 2] = -(temp_inmat[:, 0, 2] / temp_inmat[:, 0, 0])
        temp_inv_inmat[:, 1, 2] = -(temp_inmat[:, 1, 2] / temp_inmat[:, 1, 1])
        temp_inv_inmat[:, 2, 2] = 1.0
        
        #self.temp_inmat = temp_inmat
        self.temp_inv_inmat = temp_inv_inmat

        self.cam_info = {
            "batch_Rmats": self.base_c2w_Rmat.to(self.device),
            "batch_Tvecs": self.base_c2w_Tvec.to(self.device),
            "batch_inv_inmats": self.temp_inv_inmat.to(self.device).float()
        }
        

        self.code_info_i = {
            "base_iden" : base_iden,
            "base_expr" : base_expr,
            "base_text" : base_text,
            "base_illu" : base_illu,
            "inmat" : temp_inmat,
            "inv_inmat" : temp_inv_inmat.float()
        }
        '''


    '''
    def __getitem__(self, index):
        index=index+7000
        """Returns one data pair (source and target)."""
        # seq_len, fea_dim
        img_name = str(index)+'.jpg'
        mask_name=str(index)+'_mask'+'.png'
        img_path = os.path.join('/home/dataset/Macron/png',img_name)
        mask_path = os.path.join('/home/dataset/Macron/png',mask_name)
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = image.astype(np.float32)/255.0
        gt_img_size = image.shape[0]
        if gt_img_size != 512:
            image = cv2.resize(image, dsize=512, fx=0, fy=0, interpolation=cv2.INTER_LINEAR)
        mask_img =  cv2.imread(mask_path, cv2.IMREAD_UNCHANGED).astype(np.uint8)
        if mask_img.shape[0] != 512:
            mask_img = cv2.resize(mask_img, dsize=512, fx=0, fy=0, interpolation=cv2.INTER_NEAREST)
        image[mask_img < 0.5] = 1.0
        img_tensor = (torch.from_numpy(image).permute(2, 0, 1)).unsqueeze(0)


        image_ = cv2.resize(cv2.imread(img_path),(112,112,))
        image_ = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)
        image_ = image_.astype(np.float32)/255.0
        mask_img_ =  cv2.resize(cv2.imread(mask_path, cv2.IMREAD_UNCHANGED).astype(np.uint8),(112,112))
        image_[mask_img_ < 0.5] = 1.0
        img_tensor_ = (torch.from_numpy(image_).permute(2, 0, 1)).unsqueeze(0)

        input_aus=[]
        with open(os.path.join('/home/dataset/Macron/au',str(index)+".csv")) as file:
            reader = csv.reader(file)
            for  row,index in enumerate(reader):
                if row==1:
                    input_aus.append([float(index[26]),float(index[28]),float(index[31]),float(index[33]),float(index[34])])
        return img_tensor,mask_img,input_aus,img_tensor_
    '''    
    def __getitem__(self, index):
        #index=index+7000
        """Returns one data pair (source and target)."""
        # seq_len, fea_dim
        img_name_ = str(index)+'.png'
        img_name = str(index)+'.png'
        mask_name=str(index)+'_mask'+'.png'
        img_path_ = os.path.join('/home/test/Obama_q/gen/',img_name_)
        img_path = os.path.join('/home/test/Obama_q/gt/',img_name)
        mask_path = os.path.join('/home/dataset/Obama_q/png',mask_name)
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = image.astype(np.float32)/255.0
        gt_img_size = image.shape[0]
        if gt_img_size != 512:
            image = cv2.resize(image, dsize=512, fx=0, fy=0, interpolation=cv2.INTER_LINEAR)
        mask_img =  cv2.imread(mask_path, cv2.IMREAD_UNCHANGED).astype(np.uint8)
        if mask_img.shape[0] != 512:
            mask_img = cv2.resize(mask_img, dsize=512, fx=0, fy=0, interpolation=cv2.INTER_NEAREST)
        #image[mask_img < 0.5] = 1.0
        img_tensor = (torch.from_numpy(image).permute(2, 0, 1)).unsqueeze(0)

        image_png = cv2.imread(img_path_)
        image_png = cv2.cvtColor(image_png, cv2.COLOR_BGR2RGB)
        image_png = image_png.astype(np.float32)/255.0
        img_tensor_png = (torch.from_numpy(image_png).permute(2, 0, 1)).unsqueeze(0)


        image_ = cv2.resize(cv2.imread(img_path),(112,112,))
        image_ = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)
        image_ = image_.astype(np.float32)/255.0
        mask_img_ =  cv2.resize(cv2.imread(mask_path, cv2.IMREAD_UNCHANGED).astype(np.uint8),(112,112))
        image_[mask_img_ < 0.5] = 1.0
        img_tensor_ = (torch.from_numpy(image_).permute(2, 0, 1)).unsqueeze(0)

        input_aus=[]
        with open(os.path.join('/home/dataset/Obama_q/au',str(index)+".csv")) as file:
            reader = csv.reader(file)
            for  row,index in enumerate(reader):
                if row==1:
                    input_aus.append([float(index[26]),float(index[28]),float(index[31]),float(index[33]),float(index[34])])
        return img_tensor,img_tensor_png,mask_img,input_aus,img_tensor_

        '''
        dmm_name=str(index) + '_nl3dmm.pkl'
        para_3dmm_path = os.path.join('/home/dataset/Obama_q/png',dmm_name)
        with open(para_3dmm_path, "rb") as f: nl3dmm_para_dict = pkl.load(f)
        base_code = nl3dmm_para_dict["code"].float().detach().unsqueeze(0)
        base_expr_gen=base_code[:, 100:179].squeeze(1)
        return base_expr_gen
        
        file_name = self.data[index]["name"]
        audio = self.data[index]["audio"]
        vertice = self.data[index]["vertice"]
        template = self.data[index]["template"]
        if self.data_type == "train":
            subject = "_".join(file_name.split("_")[:-1])
            one_hot = self.one_hot_labels[self.subjects_dict["train"].index(subject)]
        else:
            one_hot = self.one_hot_labels
        if self.read_audio:
            return torch.FloatTensor(audio),torch.FloatTensor(vertice), torch.FloatTensor(template), torch.FloatTensor(one_hot), file_name
        else:
            return torch.FloatTensor(vertice), torch.FloatTensor(template), torch.FloatTensor(one_hot), file_name
        '''

    def __len__(self):
        return self.len

def read_data(args):
    print("Loading data...")
    data = defaultdict(dict)
    train_data = []
    valid_data = []
    test_data = []

    audio_path = os.path.join(args.data_root, args.wav_path)
    vertices_path = os.path.join(args.data_root, args.vertices_path)
    if args.read_audio: # read_audio==False when training vq to save time
        processor = Wav2Vec2Processor.from_pretrained(args.wav2vec2model_path)

    template_file = os.path.join(args.data_root, args.template_file)
    with open(template_file, 'rb') as fin:
        templates = pickle.load(fin,encoding='latin1')
    
    for r, ds, fs in os.walk(audio_path):
        for f in tqdm(fs):
            if f.endswith("wav"):
                if args.read_audio:
                    wav_path = os.path.join(r,f)
                    speech_array, sampling_rate = librosa.load(wav_path, sr=16000)
                    input_values = np.squeeze(processor(speech_array,sampling_rate=16000).input_values)
                key = f.replace("wav", "npy")
                data[key]["audio"] = input_values if args.read_audio else None
                subject_id = "_".join(key.split("_")[:-1])
                temp = templates[subject_id]
                data[key]["name"] = f
                data[key]["template"] = temp.reshape((-1)) 
                vertice_path = os.path.join(vertices_path,f.replace("wav", "npy"))
                if not os.path.exists(vertice_path):
                    del data[key]
                else:
                    if args.dataset == "vocaset":
                        data[key]["vertice"] = np.load(vertice_path,allow_pickle=True)[::2,:]#due to the memory limit
                    elif args.dataset == "BIWI":
                        data[key]["vertice"] = np.load(vertice_path,allow_pickle=True)

    subjects_dict = {}
    subjects_dict["train"] = [i for i in args.train_subjects.split(" ")]
    subjects_dict["val"] = [i for i in args.val_subjects.split(" ")]
    subjects_dict["test"] = [i for i in args.test_subjects.split(" ")]


    #train vq and pred
    splits = {'vocaset':{'train':range(1,41),'val':range(21,41),'test':range(21,41)},
    'BIWI':{'train':range(1,33),'val':range(33,37),'test':range(37,41)}}


    for k, v in data.items():
        subject_id = "_".join(k.split("_")[:-1])
        sentence_id = int(k.split(".")[0][-2:])
        if subject_id in subjects_dict["train"] and sentence_id in splits[args.dataset]['train']:
            train_data.append(v)
        if subject_id in subjects_dict["val"] and sentence_id in splits[args.dataset]['val']:
            valid_data.append(v)
        if subject_id in subjects_dict["test"] and sentence_id in splits[args.dataset]['test']:
            test_data.append(v)

    print('Loaded data: Train-{}, Val-{}, Test-{}'.format(len(train_data), len(valid_data), len(test_data)))
    return train_data, valid_data, test_data, subjects_dict

def get_dataloaders(args):
    dataset = {}
    #train_data, valid_data, test_data, subjects_dict = read_data(args)
    train_data = Dataset("train",args.read_audio)
    train_dataset, val_dataset = torch.utils.data.random_split(train_data, [7000, 1000])
    dataset["train"] = data.DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.workers)
    dataset["valid"] = data.DataLoader(dataset=val_dataset, batch_size=1, shuffle=False, num_workers=args.workers)
    #valid_data = Dataset(valid_data,subjects_dict,"val",args.read_audio)
    #dataset["valid"] = data.DataLoader(dataset=valid_data, batch_size=1, shuffle=False, num_workers=args.workers)
    #test_data = Dataset(test_data,subjects_dict,"test",args.read_audio)
    #dataset["test"] = data.DataLoader(dataset=test_data, batch_size=1, shuffle=False, num_workers=args.workers)
    return dataset

if __name__ == "__main__":
    get_dataloaders()